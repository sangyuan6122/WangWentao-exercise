Thinking1	什么是反向传播中的链式法则
神经网络的本质是复合函数，因此可以通过链式法则进行求导训练网络（也叫反向传播，通过最小化损失函数，进而反向对未知参数求导）,反向传播算法是一种利用链式法则计算微分的算法

Thinking1	请列举几种常见的激活函数，激活函数有什么作用
1）Sigmoid函数、Tanh函数、ReLu函数、Swish函数
2）激活函数是用来加入非线性因素的，提高神经网络对模型的表达能力，解决线性模型所不能解决的问题

Thinking2	利用梯度下降法训练神经网络，发现模型loss不变，可能有哪些问题？怎么解决？
可能问题:很有可能是梯度消失了，它表示神经网络迭代更新时，有些权值不更新的现象。
解决:改变激活函数，改变权值的初始化等。

Action1	"使用Pytorch编写神经网络，完成boston房价预测问题
见pytorch_boston.py

Action2	"对移动推荐系统进行可视化数据探索
见prediction_tianchi.py
